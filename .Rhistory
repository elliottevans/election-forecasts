temp$exp_weighted_avg<-temp$exp_weighted_avg-mean(temp$exp_weighted_avg)
temp$exp_weighted_avg<-temp$exp_weighted_avg/sd(temp$exp_weighted_avg)
temp$hist_dem_prob<-temp$hist_dem_prob-mean(temp$hist_dem_prob)
temp$hist_dem_prob<-temp$hist_dem_prob/sd(temp$hist_dem_prob)
##########################
#Take equal parts from each year for nearest neighbor alg
#Creates indices_2000,indices_2000,indices_2008,indices_2012
#Creates train_2000,train_2004,train_2008,train_2012
##########################
# years<-c(2000,2004,2008,2012)
# for(i in 1:length(years)){
#   train_year<-paste0("train","_",years[i])
#   assign(train_year,temp[temp$election_year==years[i],])
#   train_temp<-temp[temp$election_year==years[i],]
#   k_run_update<-floor((nrow(train_temp)/nrow(temp[temp$election_year!=2016,]))*k_run)
#   nearest<-get.knnx(
#           train_temp[,c(
#             "days_till_election"
#             ,"exp_weighted_avg"
# #            ,"hist_dem_prob"
#             )]
#         ,temp[temp$election_year==2016,c(
#             "days_till_election"
#             ,"exp_weighted_avg"
# #            ,"hist_dem_prob"
#             )]
#         ,k=k_run_update)
#
#   indices_year<-paste0("indices","_",years[i])
#   assign(indices_year,nearest$nn.index)
# }
#Take 15 distinct most similar states from each year to associate with curret states
years<-c(2000,2004,2008,2012)
for(i in 1:length(years)){
margins<-data.frame()
train_year<-paste0("train","_",years[i])
assign(train_year,temp[temp$election_year==years[i],])
train_temp_with_info<-train_temp<-temp[temp$election_year==years[i],]
train_temp<-temp[temp$election_year==years[i],c(
"days_till_election"
,"exp_weighted_avg"
,"hist_dem_prob"
)]
test_temp<-temp[temp$election_year==2016,c(
"days_till_election"
,"exp_weighted_avg"
,"hist_dem_prob"
)]
#1:nrow(test_temp)
for(j in 1:nrow(test_temp)){
#For each row in the testing set
unique_states_counter<-0
k<-1
while(unique_states_counter<15){
nearest<-get.knnx(train_temp,test_temp[j,],k)
indices<-nearest$nn.index
distances<-nearest$nn.dist
unique_states_counter<-length(unique(train_temp_with_info[unlist(as.list(indices)),]$state))
k<-k+1
}
#We now have a non-unique list of indices that includes 15 different states
train_temp_with_info_2<-train_temp_with_info[unlist(as.list(indices)),]
train_temp_with_info_2$distances<-unlist(as.list(distances))
states_wanted<-sql("
select
election_year
,state
,min(distances) as min_distances
,id
,actual_dem_margin
from train_temp_with_info_2 ttwi
group by state
order by 3 asc
limit 15
")
margins<-rbind(margins,as.list(states_wanted$actual_dem_margin))
}
if(i==1){margins_total<-margins}else{margins_total<-cbind(margins_total,margins)}
}
##########################
#Take equal parts from each year for nearest neighbor alg
##########################
polls_altered_2016<-polls_altered[polls_altered$election_year==2016,]
polls_altered_2016[polls_altered_2016$state=='PA',]
# means<-c()
# sds<-c()
# probs<-c()
# for(i in 1:nrow(polls_altered_2016)){
#   margins<-c(train_2000[indices_2000[i,],]$actual_dem_margin
#              ,train_2004[indices_2004[i,],]$actual_dem_margin
#              ,train_2008[indices_2008[i,],]$actual_dem_margin
#              ,train_2012[indices_2012[i,],]$actual_dem_margin)
#   means<-append(means,mean(margins))
#   sds<-append(sds,sd(margins))
#   probability<-pnorm(q=0,mean=mean(margins),sd=sd(margins),lower.tail = FALSE)
#   probs<-append(probs,probability)
# }
means<-c()
sds<-c()
probs<-c()
for(i in 1:nrow(polls_altered_2016)){
mean<-mean(unlist(as.list(margins_total[i,])))
sd<-sd(unlist(as.list(margins_total[i,])))
means<-append(means,mean)
sds<-append(sds,sd)
probability<-pnorm(q=0,mean=mean,sd=sd,lower.tail = FALSE)
probs<-append(probs,probability)
}
polls_altered_2016$probs<-probs
polls_altered_2016$mean<-means
polls_altered_2016$sd<-sds
#########################################################################################################################################
# NEAREST NEIGHBOR LEARNING
#########################################################################################################################################
polls_altered_final<-data.frame(cbind(polls_altered,prob_weighted_dem=NA,prob_weighted_rep=NA))
polls_altered_final<-melt(polls_altered_final,id=c('id','election_year','state','date','days_till_election','dem_plus_minus',
'exp_weighted_avg','exp_weights','prop_weighted_avg','prop_weights','hist_dem_prob','actual','actual_dem_margin','actual_binary_dem'))
names(polls_altered_final)[ncol(polls_altered_final)-1]<-'prediction'
polls_altered_final<-sql("
select
paf.*
,mean
,sd
,case when prediction='prob_weighted_rep' then 1-probs
when prediction='prob_weighted_dem' then probs
end as nearest_neighbor_value
from polls_altered_final paf
left join polls_altered_2016 pa on pa.id=paf.id
")
polls_altered_final<-polls_altered_final[,!(colnames(polls_altered_final) %in% c('value'))]
####################################
# Actually create the models
####################################
####################################
# Set indicators for the state's most current prediction date
####################################
#Make indicators for the last prediction for each state-year
temp<-sql("
select
election_year
,State
,min(days_till_election) as final_poll_days_till_election
from polls_altered_final
group by 1,2
")
polls_altered_final<-sql("
select
paf.*
,case when final_poll_days_till_election=days_till_election then 1 else 0 end as final_prediction_ind
from polls_altered_final paf
inner join temp t on paf.election_year=t.election_year and paf.State=t.State
")
write.csv(polls_altered_final,'forecasts\\polls_altered_final.csv',row.names = FALSE)
####################################
# Set indicators for the state's most current prediction date
####################################
#########################################################################################################################################
# ELECTION SIMULATION
#########################################################################################################################################
#HERE TO EDIT
state_odds<-sqldf("
select
msr.state
,abb
,electoral_votes
,ifnull(dem_prob,msr.hist_dem_prob) as dem_prob
,mean
,sd
from master_state_ref msr
left join
(
select
state
,hist_dem_prob
,nearest_neighbor_value as dem_prob
,mean
,sd
from polls_altered_final paf
where final_prediction_ind=1
and election_year=2016
and prediction='prob_weighted_dem'
) as t1
on msr.abb=t1.state
")
state_odds<-sql("
select
so.state
,so.abb
,so.electoral_votes
,dem_prob
,ifnull(mean,(`2000_dem_margin`+`2004_dem_margin`+`2008_dem_margin`+`2012_dem_margin`)/4) as mean
,ifnull(sd,sqrt(power((((`2000_dem_margin`+`2004_dem_margin`+`2008_dem_margin`+`2012_dem_margin`)/4)-`2000_dem_margin`),2)+
power((((`2000_dem_margin`+`2004_dem_margin`+`2008_dem_margin`+`2012_dem_margin`)/4)-`2004_dem_margin`),2)+
power((((`2000_dem_margin`+`2004_dem_margin`+`2008_dem_margin`+`2012_dem_margin`)/4)-`2008_dem_margin`),2)+
power((((`2000_dem_margin`+`2004_dem_margin`+`2008_dem_margin`+`2012_dem_margin`)/4)-`2012_dem_margin`),2))) as sd
from state_odds so
inner join master_state_ref msr on so.state=msr.state
")
state_odds
#########################################################################################################################################
# CREATE WEIGHTED POLLING AVERAGES
#########################################################################################################################################
temp1<-sql("
Select
id
,election_year
,state as state
,date
,days_till_election
,sum(case when party='D' then value else 0 end) -
sum(case when party='R' then value else 0 end) as dem_plus_minus
from polls
group by 1,2,3
")
names(temp1)<-c('id','election_year','state','date','days_till_election','dem_plus_minus')
#Create running averages of polling margins
years<-c(2000,2004,2008,2012,2016)
polls_altered<-data.frame()
prop_weights<-c()
prop_weight_list<-c()
#1:length(years)
for(l in 1:length(years)){
year<-years[l]
temp2<-temp1[temp1$election_year==year,]
states<-unique(temp2$state)
#1:length(states)
for(m in 1:length(states)){
state<-states[m]
temp3<-temp2[temp2$state==state,]
temp4<-temp3[order(-temp3$days_till_election),]
exp_weighted_avg<-c()
running_avg<-c()
prop_weighted_avg<-c()
for(p in 1:nrow(temp4)){
#Note that we give more weight to polls closer to the election day
#EXPONENTIAL WEIGHTING
temp5<-temp4[1:p,]
n<-nrow(temp5)
exp_weights<-c()
weight_sum<-0
for(i in 1:n){
sum<-1
j<-1
while(j >=1 && j<=(n-1)){
sum_temp<-0
k<-i
while(k>=i && k<=j){
sum_temp<-sum_temp+temp5$days_till_election[k]/temp5$days_till_election[k+1]
k<-k+1
}
if(i>j){sum<-sum+0}else{sum<-sum+(1.3^sum_temp)}
j<-j+1
}
sum<-(1-weight_sum)*(sum^(-1))
weight_sum<-weight_sum+sum
exp_weights<-append(exp_weights,sum)
}
exp_weighted_avg<-append(exp_weighted_avg,sum(temp5$dem_plus_minus*exp_weights))
#PROPORTIONAL WEIGHTING
running_avg<-append(running_avg,sum(temp4$dem_plus_minus[1:p])/p)
prop_weighted_avg<-append(prop_weighted_avg,sum(temp4$dem_plus_minus[1:p] * (sort(temp4$days_till_election[1:p]))/sum(temp4$days_till_election[1:p])))
prop_weights<-(sort(temp4$days_till_election[1:p]))/sum(temp4$days_till_election[1:p])
}
prop_weight_list<-append(prop_weight_list,prop_weights)
temp5<-data.frame(cbind(temp5,exp_weighted_avg,exp_weights,prop_weighted_avg))
polls_altered<-data.frame(rbind(polls_altered,temp5))
}
}
polls_altered<-data.frame(cbind(polls_altered,prop_weight_list))
names(polls_altered)[ncol(polls_altered)]<-'prop_weights'
polls_altered<-sql("
select
temp1.*
,case when actual='D' then 1
when actual='R' then 0
when election_year=2016 then '' end as actual_binary_dem
from
(
select
pa.*
,case when pa.election_year=2000 then hist_dem_prob_2000
when pa.election_year=2004 then hist_dem_prob_2004
when pa.election_year=2008 then hist_dem_prob_2008
when pa.election_year=2012 then hist_dem_prob_2012
when pa.election_year=2016 then hist_dem_prob end as hist_dem_prob
,case when pa.election_year=2000 then msr.`2000`
when pa.election_year=2004 then msr.`2004`
when pa.election_year=2008 then msr.`2008`
when pa.election_year=2012 then msr.`2012`
when pa.election_year=2016 then '' end as actual
,case when pa.election_year=2000 then msr.`2000_dem_margin`
when pa.election_year=2004 then msr.`2004_dem_margin`
when pa.election_year=2008 then msr.`2008_dem_margin`
when pa.election_year=2012 then msr.`2012_dem_margin`
when pa.election_year=2016 then '' end as actual_dem_margin
from polls_altered pa
inner join master_state_ref msr on msr.abb=pa.state
) as temp1
")
polls_altered[polls_altered$election_year==2016,'actual_binary_dem']<-''
#########################################################################################################################################
# CREATE WEIGHTED POLLING AVERAGES
#########################################################################################################################################
#########################################################################################################################################
# NEAREST NEIGHBOR LEARNING
#########################################################################################################################################
#k_run<-100
temp<-polls_altered
#standardize metrics for nearest neighbor algorithm
temp$days_till_election<-temp$days_till_election-mean(temp$days_till_election)
temp$days_till_election<-temp$days_till_election/sd(temp$days_till_election)
temp$exp_weighted_avg<-temp$exp_weighted_avg-mean(temp$exp_weighted_avg)
temp$exp_weighted_avg<-temp$exp_weighted_avg/sd(temp$exp_weighted_avg)
temp$hist_dem_prob<-temp$hist_dem_prob-mean(temp$hist_dem_prob)
temp$hist_dem_prob<-temp$hist_dem_prob/sd(temp$hist_dem_prob)
##########################
#Take equal parts from each year for nearest neighbor alg
#Creates indices_2000,indices_2000,indices_2008,indices_2012
#Creates train_2000,train_2004,train_2008,train_2012
##########################
# years<-c(2000,2004,2008,2012)
# for(i in 1:length(years)){
#   train_year<-paste0("train","_",years[i])
#   assign(train_year,temp[temp$election_year==years[i],])
#   train_temp<-temp[temp$election_year==years[i],]
#   k_run_update<-floor((nrow(train_temp)/nrow(temp[temp$election_year!=2016,]))*k_run)
#   nearest<-get.knnx(
#           train_temp[,c(
#             "days_till_election"
#             ,"exp_weighted_avg"
# #            ,"hist_dem_prob"
#             )]
#         ,temp[temp$election_year==2016,c(
#             "days_till_election"
#             ,"exp_weighted_avg"
# #            ,"hist_dem_prob"
#             )]
#         ,k=k_run_update)
#
#   indices_year<-paste0("indices","_",years[i])
#   assign(indices_year,nearest$nn.index)
# }
#Take 15 distinct most similar states from each year to associate with curret states
years<-c(2000,2004,2008,2012)
for(i in 1:length(years)){
margins<-data.frame()
train_year<-paste0("train","_",years[i])
assign(train_year,temp[temp$election_year==years[i],])
train_temp_with_info<-train_temp<-temp[temp$election_year==years[i],]
train_temp<-temp[temp$election_year==years[i],c(
"days_till_election"
,"exp_weighted_avg"
,"hist_dem_prob"
)]
test_temp<-temp[temp$election_year==2016,c(
"days_till_election"
,"exp_weighted_avg"
,"hist_dem_prob"
)]
#1:nrow(test_temp)
for(j in 1:nrow(test_temp)){
#For each row in the testing set
unique_states_counter<-0
k<-1
while(unique_states_counter<15){
nearest<-get.knnx(train_temp,test_temp[j,],k)
indices<-nearest$nn.index
distances<-nearest$nn.dist
unique_states_counter<-length(unique(train_temp_with_info[unlist(as.list(indices)),]$state))
k<-k+1
}
#We now have a non-unique list of indices that includes 15 different states
train_temp_with_info_2<-train_temp_with_info[unlist(as.list(indices)),]
train_temp_with_info_2$distances<-unlist(as.list(distances))
states_wanted<-sql("
select
election_year
,state
,min(distances) as min_distances
,id
,actual_dem_margin
from train_temp_with_info_2 ttwi
group by state
order by 3 asc
limit 15
")
margins<-rbind(margins,as.list(states_wanted$actual_dem_margin))
}
if(i==1){margins_total<-margins}else{margins_total<-cbind(margins_total,margins)}
}
##########################
#Take equal parts from each year for nearest neighbor alg
##########################
polls_altered_2016<-polls_altered[polls_altered$election_year==2016,]
# means<-c()
# sds<-c()
# probs<-c()
# for(i in 1:nrow(polls_altered_2016)){
#   margins<-c(train_2000[indices_2000[i,],]$actual_dem_margin
#              ,train_2004[indices_2004[i,],]$actual_dem_margin
#              ,train_2008[indices_2008[i,],]$actual_dem_margin
#              ,train_2012[indices_2012[i,],]$actual_dem_margin)
#   means<-append(means,mean(margins))
#   sds<-append(sds,sd(margins))
#   probability<-pnorm(q=0,mean=mean(margins),sd=sd(margins),lower.tail = FALSE)
#   probs<-append(probs,probability)
# }
means<-c()
sds<-c()
probs<-c()
for(i in 1:nrow(polls_altered_2016)){
mean<-mean(unlist(as.list(margins_total[i,])))
sd<-sd(unlist(as.list(margins_total[i,])))
means<-append(means,mean)
sds<-append(sds,sd)
probability<-pnorm(q=0,mean=mean,sd=sd,lower.tail = FALSE)
probs<-append(probs,probability)
}
polls_altered_2016$probs<-probs
polls_altered_2016$mean<-means
polls_altered_2016$sd<-sds
#########################################################################################################################################
# NEAREST NEIGHBOR LEARNING
#########################################################################################################################################
polls_altered_final<-data.frame(cbind(polls_altered,prob_weighted_dem=NA,prob_weighted_rep=NA))
polls_altered_final<-melt(polls_altered_final,id=c('id','election_year','state','date','days_till_election','dem_plus_minus',
'exp_weighted_avg','exp_weights','prop_weighted_avg','prop_weights','hist_dem_prob','actual','actual_dem_margin','actual_binary_dem'))
names(polls_altered_final)[ncol(polls_altered_final)-1]<-'prediction'
polls_altered_final<-sql("
select
paf.*
,mean
,sd
,case when prediction='prob_weighted_rep' then 1-probs
when prediction='prob_weighted_dem' then probs
end as nearest_neighbor_value
from polls_altered_final paf
left join polls_altered_2016 pa on pa.id=paf.id
")
polls_altered_final<-polls_altered_final[,!(colnames(polls_altered_final) %in% c('value'))]
####################################
# Actually create the models
####################################
####################################
# Set indicators for the state's most current prediction date
####################################
#Make indicators for the last prediction for each state-year
temp<-sql("
select
election_year
,State
,min(days_till_election) as final_poll_days_till_election
from polls_altered_final
group by 1,2
")
polls_altered_final<-sql("
select
paf.*
,case when final_poll_days_till_election=days_till_election then 1 else 0 end as final_prediction_ind
from polls_altered_final paf
inner join temp t on paf.election_year=t.election_year and paf.State=t.State
")
write.csv(polls_altered_final,'forecasts\\polls_altered_final.csv',row.names = FALSE)
####################################
# Set indicators for the state's most current prediction date
####################################
#########################################################################################################################################
# ELECTION SIMULATION
#########################################################################################################################################
#HERE TO EDIT
state_odds<-sqldf("
select
msr.state
,abb
,electoral_votes
,ifnull(dem_prob,msr.hist_dem_prob) as dem_prob
,mean
,sd
from master_state_ref msr
left join
(
select
state
,hist_dem_prob
,nearest_neighbor_value as dem_prob
,mean
,sd
from polls_altered_final paf
where final_prediction_ind=1
and election_year=2016
and prediction='prob_weighted_dem'
) as t1
on msr.abb=t1.state
")
state_odds<-sql("
select
so.state
,so.abb
,so.electoral_votes
,dem_prob
,ifnull(mean,(`2000_dem_margin`+`2004_dem_margin`+`2008_dem_margin`+`2012_dem_margin`)/4) as mean
,ifnull(sd,sqrt(power((((`2000_dem_margin`+`2004_dem_margin`+`2008_dem_margin`+`2012_dem_margin`)/4)-`2000_dem_margin`),2)+
power((((`2000_dem_margin`+`2004_dem_margin`+`2008_dem_margin`+`2012_dem_margin`)/4)-`2004_dem_margin`),2)+
power((((`2000_dem_margin`+`2004_dem_margin`+`2008_dem_margin`+`2012_dem_margin`)/4)-`2008_dem_margin`),2)+
power((((`2000_dem_margin`+`2004_dem_margin`+`2008_dem_margin`+`2012_dem_margin`)/4)-`2012_dem_margin`),2))) as sd
from state_odds so
inner join master_state_ref msr on so.state=msr.state
")
polls_altered_2016[polls_altered_2016$state=='PA',]
polls_altered_2016[polls_altered_2016$state=='OH',]
state_odds
polls_altered_2016[polls_altered_2016$state=='FL',]
